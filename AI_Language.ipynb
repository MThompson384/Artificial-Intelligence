{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMdjQuYB6vlCExgi4+zYBTg"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AI Language #\n",
        "\n",
        "See coding instructions given on paper from instructor.\n",
        "\n",
        "1.   Write the entropy function for binary classification from scratch using only Python's math module. DO NOT USE NUMPY\n",
        "2.   Do NOT call built-in entropy function from any Python library.\n",
        "3. Use the math library only. Do not use any other library.\n",
        "4. You have to write the entropy function from scratch on your own.\n",
        "5. Your entropy function should take a probability value for one of the two calsses as input, and output its entropy value.\n",
        "6. Call your entropy function using 0.2 as input.\n"
      ],
      "metadata": {
        "id": "8wtE_72Iga1C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19iBpfqcgJ_J"
      },
      "outputs": [],
      "source": [
        "#Math Library\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**-Replace xxx with the appropriate value**\n",
        "\n",
        "**Q4-0-0:** Print the output of the function call as \"The entorpy value of probability 0.2 is xxx\"\n",
        "\n",
        "7. Call your entropy function using 0.8 as input\n",
        "\n",
        "**Q4-0-1** Print the outut of the function call as \"The entropy value of probability 0.8 is xxx\"\n",
        "\n",
        "8. Call your entropy function using 0.5 as input\n",
        "\n",
        "**Q4-0-2** Print the output of the function call as \"The entropy value of probability 0.5 is xxx\""
      ],
      "metadata": {
        "id": "OrJZzOTwke_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#defining entropy for a binary classification\n",
        "def entropy(p):\n",
        "  # Handle cases where p is 0 or 1\n",
        "    if p == 0 or p == 1:\n",
        "        return 0\n",
        "    # Calculate entropy using the full formula\n",
        "    return -p * math.log2(p) - (1 - p) * math.log2(1 - p)\n",
        "\n",
        "#calling the entropy function with p=0.2\n",
        "result = entropy(0.2)\n",
        "\n",
        "#Q4-0-0: print the output of the function call as' The entropy value of probability 0.2 is xxx'\n",
        "print(\"The entropy value of probability 0.2 is\", result)\n",
        "\n",
        "#calling the entropy function with p=0.8\n",
        "result1 = entropy(0.8)\n",
        "\n",
        "#Q4-0-1: print the output of the function call as' The entropy value of probability 0.8 is xxx'\n",
        "print(\"The entropy value of probability 0.8 is\", result1)\n",
        "\n",
        "#calling the entropy function with p=0.5\n",
        "result2 = entropy(0.5)\n",
        "\n",
        "#Q4-0-2: print the output of the function call as' The entropy value of probability 0.5 is xxx'\n",
        "print(\"The entropy value of probability 0.5 is\", result2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIBbA3twkCCF",
        "outputId": "38cf40b6-2205-40a8-b170-7c028b2e8d7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The entropy value of probability 0.2 is 0.7219280948873623\n",
            "The entropy value of probability 0.8 is 0.7219280948873623\n",
            "The entropy value of probability 0.5 is 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# M4 Assignment 1: RNN for Time Series Prediction\n",
        "\n",
        "This assignment is based on the Time Series Prediction lab 10.9.6 from ISLP Chapter 10.\n",
        "\n",
        "\n",
        "\n",
        "*   Please use the texbook lab as a reference\n",
        "*   You should write your model using Tensorflow\n",
        "*   The goal is to predict **log_volume** using lagged data\n",
        "\n"
      ],
      "metadata": {
        "id": "s2zE0eG2mV-j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 0: Load Libraries**"
      ],
      "metadata": {
        "id": "vTzAH_7mpzqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "random.seed(1693)\n",
        "np.random.seed(1693)\n",
        "tf.random.set_seed(1693)"
      ],
      "metadata": {
        "id": "_8qvKkVTqgYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Load & Prep Dataframe**\n",
        "\n",
        "\n",
        "\n",
        "1.   Load the NYSE datset from the NYSE.csv file available\n",
        "2.   The data column gives you the timestamps of the time series\n",
        "3.   Train column indicates True for records to be used in the train set, and False for those to be used in the test set\n",
        "4.   For this step, let's keep only these 3 columns: 'DJ_return', 'log_volune', 'log_volatility'\n",
        "5.   Standardize all 3 columns using ScikitLearn's StandardScaler\n",
        "\n",
        "In the starter code given below:\n",
        "*   cols is a list of the names of these 3 columns\n",
        "*   X is a dataframe that contains only these 3 columns from NYSE.csv\n",
        "\n"
      ],
      "metadata": {
        "id": "MrqCW2vXQbg3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the NYSE dataset\n",
        "df = pd.read_csv('NYSE.csv')\n",
        "\n",
        "#Define the columns to keep\n",
        "cols = ['DJ_return', 'log_volume', 'log_volatility']\n",
        "\n",
        "#Create a new copy with only the specified columns\n",
        "X = df[cols].copy()\n",
        "\n",
        "#Standardize the columns using StandardScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X[cols] = scaler.fit_transform(X[cols])\n",
        "\n",
        "#Q4-1-0 Print '0. the shape of dataframe X:xxx\n",
        "print(f'the shape of dataframe X:', X.shape)\n",
        "\n",
        "#4-1-1 Print '1. the first record of datarame X:xxx\n",
        "print(f'the first record of dataframe X:', X.iloc[0])\n"
      ],
      "metadata": {
        "id": "4xetJvvyQhFr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bba8edfa-5ece-4a9d-8eb2-70b4260f799e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the shape of dataframe X: (6051, 3)\n",
            "the first record of dataframe X: DJ_return        -0.549823\n",
            "log_volume        0.175075\n",
            "log_volatility   -4.357078\n",
            "Name: 0, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use code from the textbook lab to set up lagged versions of these 3 data columns.\n",
        "\n",
        "Add column 'train' from the orginial dataset to the current dataframe X as the last column (to the right)"
      ],
      "metadata": {
        "id": "ef4RaB-TbniR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Add Lagged versions of the 3 columns\n",
        "lags = 5\n",
        "for lag in range(1, lags + 1):\n",
        "  for col in cols:\n",
        "    X[f'{col}_lag_{lag}'] = X[col].shift(lag)\n",
        "\n",
        "#Add the 'train' column from the original dataset to X\n",
        "X['train'] = df['train']\n",
        "\n",
        "#Q4-1-2 Print '2. the shape of dataframe X with lags:xxx\n",
        "print(f'the shape of dataframe X with lags:', X.shape)\n",
        "\n",
        "#Q4-1-3 Print '3. the first record of dataframe X with lags:xxx\n",
        "print(f'the first record of dataframe X with lags:', X.iloc[0])\n",
        "\n",
        "#Drop rows with missing values\n",
        "X = X.dropna()\n",
        "\n",
        "#Q4-1-4 Print '4. the shape of dataframe X with lags:xxx\n",
        "print(f'the shape of dataframe X with lags:', X.shape)\n",
        "\n",
        "#Q4-1-5 Print '5. the first record of dataframe X with lags:xxx\n",
        "print(f'the first record of dataframe X with lags:', X.iloc[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8_FHJE9cOa4",
        "outputId": "98858a0d-1a08-4838-f840-e4a49ea699ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the shape of dataframe X with lags: (6051, 19)\n",
            "the first record of dataframe X with lags: DJ_return              -0.549823\n",
            "log_volume              0.175075\n",
            "log_volatility         -4.357078\n",
            "DJ_return_lag_1              NaN\n",
            "log_volume_lag_1             NaN\n",
            "log_volatility_lag_1         NaN\n",
            "DJ_return_lag_2              NaN\n",
            "log_volume_lag_2             NaN\n",
            "log_volatility_lag_2         NaN\n",
            "DJ_return_lag_3              NaN\n",
            "log_volume_lag_3             NaN\n",
            "log_volatility_lag_3         NaN\n",
            "DJ_return_lag_4              NaN\n",
            "log_volume_lag_4             NaN\n",
            "log_volatility_lag_4         NaN\n",
            "DJ_return_lag_5              NaN\n",
            "log_volume_lag_5             NaN\n",
            "log_volatility_lag_5         NaN\n",
            "train                       True\n",
            "Name: 0, dtype: object\n",
            "the shape of dataframe X with lags: (6046, 19)\n",
            "the first record of dataframe X with lags: DJ_return              -1.304126\n",
            "log_volume              0.605918\n",
            "log_volatility         -1.366028\n",
            "DJ_return_lag_1          0.04634\n",
            "log_volume_lag_1        0.224779\n",
            "log_volatility_lag_1    -2.50097\n",
            "DJ_return_lag_2        -0.431397\n",
            "log_volume_lag_2        0.935176\n",
            "log_volatility_lag_2   -2.366521\n",
            "DJ_return_lag_3         0.434813\n",
            "log_volume_lag_3        2.283789\n",
            "log_volatility_lag_3   -2.418037\n",
            "DJ_return_lag_4           0.9052\n",
            "log_volume_lag_4        1.517291\n",
            "log_volatility_lag_4   -2.529058\n",
            "DJ_return_lag_5        -0.549823\n",
            "log_volume_lag_5        0.175075\n",
            "log_volatility_lag_5   -4.357078\n",
            "train                       True\n",
            "Name: 5, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Create the Y response target using the 'log_volume' column from dataframe X\n",
        "* Extract the 'train' column from dataframe X as a separate variable called train. Drop the 'train' column from dataframe X\n",
        "* Later on we will use the train variable to split the dataset into train vs test\n",
        "* Drop the current day's DJ_return (the 'DJ_return' column) and log_volatility from dataframe X\n",
        "* In other words, remove these two X features, and also the Y response that came from dataframe X"
      ],
      "metadata": {
        "id": "xyuPuKN5iOeJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#print(X.columns)\n",
        "\n",
        "# Create the Y response target using the 'log_volume' column from dataframe X\n",
        "Y = X['log_volume'].copy()\n",
        "\n",
        "# Extract the 'train' column from dataframe X as a separate variable called train\n",
        "train = X['train'].copy()  # train is a separate variable for splitting the dataset\n",
        "\n",
        "# Drop the 'train' column from dataframe X\n",
        "X = X.drop(columns=['train'])\n",
        "\n",
        "# Drop the current day's 'DJ_return' and 'log_volatility' from dataframe X\n",
        "X = X.drop(columns=['DJ_return', 'log_volatility'])\n",
        "\n",
        "#Q4-1-6 Print '6. the first 3 records of the Y target:xxx'\n",
        "print(f'the first 3 records of the Y target:', Y.iloc[:3])\n",
        "\n",
        "#Q4-1-7 Print '7. the first 3 records of the train variable:xxx'\n",
        "print(f'the first 3 records of the train variable:', train.iloc[:3])\n",
        "\n",
        "#Q4-1-8 Print '8. the first 3 records of dataframe X:xxx'\n",
        "print(f'the first 3 records of dataframe X:', X.iloc[:3])\n",
        "\n",
        "#Q4-1-8 Print '8. the first 3 records of the X features:xxx'\n",
        "print(f'the first 3 records of the X features:', X.iloc[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fjCKamYijUh",
        "outputId": "867ff484-bdf6-4ef0-f514-9eefd3c78498"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the first 3 records of the Y target: 5    0.605918\n",
            "6   -0.013661\n",
            "7    0.042552\n",
            "Name: log_volume, dtype: float64\n",
            "the first 3 records of the train variable: 5    True\n",
            "6    True\n",
            "7    True\n",
            "Name: train, dtype: bool\n",
            "the first 3 records of dataframe X:    log_volume  DJ_return_lag_1  log_volume_lag_1  log_volatility_lag_1  \\\n",
            "5    0.605918         0.046340          0.224779             -2.500970   \n",
            "6   -0.013661        -1.304126          0.605918             -1.366028   \n",
            "7    0.042552        -0.006294         -0.013661             -1.505667   \n",
            "\n",
            "   DJ_return_lag_2  log_volume_lag_2  log_volatility_lag_2  DJ_return_lag_3  \\\n",
            "5        -0.431397          0.935176             -2.366521         0.434813   \n",
            "6         0.046340          0.224779             -2.500970        -0.431397   \n",
            "7        -1.304126          0.605918             -1.366028         0.046340   \n",
            "\n",
            "   log_volume_lag_3  log_volatility_lag_3  DJ_return_lag_4  log_volume_lag_4  \\\n",
            "5          2.283789             -2.418037         0.905200          1.517291   \n",
            "6          0.935176             -2.366521         0.434813          2.283789   \n",
            "7          0.224779             -2.500970        -0.431397          0.935176   \n",
            "\n",
            "   log_volatility_lag_4  DJ_return_lag_5  log_volume_lag_5  \\\n",
            "5             -2.529058        -0.549823          0.175075   \n",
            "6             -2.418037         0.905200          1.517291   \n",
            "7             -2.366521         0.434813          2.283789   \n",
            "\n",
            "   log_volatility_lag_5  \n",
            "5             -4.357078  \n",
            "6             -2.529058  \n",
            "7             -2.418037  \n",
            "the first 3 records of the X features:    log_volume  DJ_return_lag_1  log_volume_lag_1  log_volatility_lag_1  \\\n",
            "5    0.605918         0.046340          0.224779             -2.500970   \n",
            "6   -0.013661        -1.304126          0.605918             -1.366028   \n",
            "7    0.042552        -0.006294         -0.013661             -1.505667   \n",
            "\n",
            "   DJ_return_lag_2  log_volume_lag_2  log_volatility_lag_2  DJ_return_lag_3  \\\n",
            "5        -0.431397          0.935176             -2.366521         0.434813   \n",
            "6         0.046340          0.224779             -2.500970        -0.431397   \n",
            "7        -1.304126          0.605918             -1.366028         0.046340   \n",
            "\n",
            "   log_volume_lag_3  log_volatility_lag_3  DJ_return_lag_4  log_volume_lag_4  \\\n",
            "5          2.283789             -2.418037         0.905200          1.517291   \n",
            "6          0.935176             -2.366521         0.434813          2.283789   \n",
            "7          0.224779             -2.500970        -0.431397          0.935176   \n",
            "\n",
            "   log_volatility_lag_4  DJ_return_lag_5  log_volume_lag_5  \\\n",
            "5             -2.529058        -0.549823          0.175075   \n",
            "6             -2.418037         0.905200          1.517291   \n",
            "7             -2.366521         0.434813          2.283789   \n",
            "\n",
            "   log_volatility_lag_5  \n",
            "5             -4.357078  \n",
            "6             -2.529058  \n",
            "7             -2.418037  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To fit the RNN, we must reshape the X dataframe, as the RNN layer will expect 5 lagged versions of each feature as indicated by the (5,3) shape of the RNN layer below.\n",
        "\n",
        "1. We first ensure the columns of our X dataframe are such that a reshaped matrix will have the variables correctly lagged. We use the reindex() method to do this.\n",
        "\n",
        "The RNN layer also expects the first row of each observation to be earliest in time. So we must revers the current order.\n",
        "\n",
        "Follow the textbook lab code to reorder/reindex the columns properly."
      ],
      "metadata": {
        "id": "6QDzLgsx21eZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure the columns of X are in the correct order for reshaping\n",
        "ordered_cols = []\n",
        "for lag in range(5, 0, -1):  # Loop from lag 5 to lag 1 (reverse order)\n",
        "    for col in cols:  # Loop through each feature\n",
        "        ordered_cols.append(f'{col}_lag_{lag}')  # Add the lagged column to the ordered list\n",
        "\n",
        "# Reindex the dataframe X to the ordered columns\n",
        "X = X.reindex(columns=ordered_cols)\n",
        "\n",
        "#Q4-1-9 Print '9. the first 3 records of X after reindexting: xxx'\n",
        "print(f'the first 3 records of X after reindexting:', X.iloc[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGNg0jSbDjk8",
        "outputId": "8ab07e70-426b-4d7a-91d6-c7baa0af0983"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the first 3 records of X after reindexting:    DJ_return_lag_5  log_volume_lag_5  log_volatility_lag_5  DJ_return_lag_4  \\\n",
            "5        -0.549823          0.175075             -4.357078         0.905200   \n",
            "6         0.905200          1.517291             -2.529058         0.434813   \n",
            "7         0.434813          2.283789             -2.418037        -0.431397   \n",
            "\n",
            "   log_volume_lag_4  log_volatility_lag_4  DJ_return_lag_3  log_volume_lag_3  \\\n",
            "5          1.517291             -2.529058         0.434813          2.283789   \n",
            "6          2.283789             -2.418037        -0.431397          0.935176   \n",
            "7          0.935176             -2.366521         0.046340          0.224779   \n",
            "\n",
            "   log_volatility_lag_3  DJ_return_lag_2  log_volume_lag_2  \\\n",
            "5             -2.418037        -0.431397          0.935176   \n",
            "6             -2.366521         0.046340          0.224779   \n",
            "7             -2.500970        -1.304126          0.605918   \n",
            "\n",
            "   log_volatility_lag_2  DJ_return_lag_1  log_volume_lag_1  \\\n",
            "5             -2.366521         0.046340          0.224779   \n",
            "6             -2.500970        -1.304126          0.605918   \n",
            "7             -1.366028        -0.006294         -0.013661   \n",
            "\n",
            "   log_volatility_lag_1  \n",
            "5             -2.500970  \n",
            "6             -1.366028  \n",
            "7             -1.505667  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reshape dataframe X as a 3-D Numpy array such that each record/ row has the shape of (5,3). Each row represents a lagged version of the 3 variables in the shape of (5,3)"
      ],
      "metadata": {
        "id": "HlK_BBrHD2n8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure the columns of X are in the correct order for reshaping\n",
        "ordered_cols = []\n",
        "for lag in range(1, 6):  # Loop from lag 1 to lag 5\n",
        "    for col in cols:  # Loop through each feature\n",
        "        ordered_cols.append(f'{col}_lag_{lag}')  # Add the lagged column to the ordered list\n",
        "\n",
        "# Reindex the dataframe X to the ordered columns\n",
        "X = X.reindex(columns=ordered_cols)\n",
        "\n",
        "# Reshape X to the shape (samples, timesteps, features)\n",
        "X_rnn = X.to_numpy().reshape((-1, 5, 3))  # Shape: (samples, 5, 3)\n",
        "\n",
        "#Q4-1-10: Print '10. the shape of X after reshaping: xxx\n",
        "print(f'the shape of X after reshaping:', X_rnn.shape)\n",
        "\n",
        "#Q4-1-11: Print '11. the first 2 records of X after reshaping: xxx\n",
        "print(f'the first 2 records of X after reshaping:', X_rnn[:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeNmyPToEFOU",
        "outputId": "febb8971-3483-4520-c71a-6031af4d3faa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the shape of X after reshaping: (6046, 5, 3)\n",
            "the first 2 records of X after reshaping: [[[ 0.04634026  0.22477858 -2.5009701 ]\n",
            "  [-0.43139673  0.93517558 -2.36652094]\n",
            "  [ 0.43481275  2.28378937 -2.41803694]\n",
            "  [ 0.90519995  1.51729071 -2.52905765]\n",
            "  [-0.54982334  0.17507497 -4.35707786]]\n",
            "\n",
            " [[-1.30412619  0.60591805 -1.366028  ]\n",
            "  [ 0.04634026  0.22477858 -2.5009701 ]\n",
            "  [-0.43139673  0.93517558 -2.36652094]\n",
            "  [ 0.43481275  2.28378937 -2.41803694]\n",
            "  [ 0.90519995  1.51729071 -2.52905765]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Step 2: Prep Train vs Test Sets**\n",
        "\n",
        " * Set up my X_train, X_test, Y_train, and Y_test using the X dataframe, Y response target, and the train variable you have created above\n",
        "\n",
        " *Include recors where train = True in the train set, and train = False in the test set"
      ],
      "metadata": {
        "id": "vBn_iG3ZEv2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into train and test sets using the train variable\n",
        "X_train = X_rnn[train]  # X_train includes records where train = True\n",
        "X_test = X_rnn[~train]  # X_test includes records where train = False\n",
        "\n",
        "Y_train = Y[train]  # Y_train includes records where train = True\n",
        "Y_test = Y[~train]  # Y_test includes records where train = False"
      ],
      "metadata": {
        "id": "pzHnvdg6FWqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Train Model**\n",
        "\n",
        "Confirgure a Keras Sequential model with\n",
        "1. proper input shape\n",
        "2. SimpleRNN layer with 12 hidden units\n",
        "3. relu activation function\n",
        "4. 10% dropout\n",
        "5. proper output layer\n",
        "\n",
        "Do not name the model or any of the layers"
      ],
      "metadata": {
        "id": "XBVIJIktFmXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dropout, Dense\n",
        "\n",
        "# Configure the Keras Sequential model\n",
        "model = Sequential([\n",
        "    SimpleRNN(12, activation='relu', input_shape=(5, 3)),  # SimpleRNN layer with 12 hidden units and relu activation\n",
        "    Dropout(0.1), # 10% dropout\n",
        "    Dense(1)  # Output layer with 1 unit (for regression)\n",
        "])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "of2X0Y05GDyG",
        "outputId": "ea5fe442-38b7-47f8-dba2-6886c61c596f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │             \u001b[38;5;34m192\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m13\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m205\u001b[0m (820.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">205</span> (820.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m205\u001b[0m (820.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">205</span> (820.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile the model with\n",
        "\n",
        "1. adam optimizer\n",
        "2. MSE as the loss\n",
        "3. MSE as the metric\n",
        "\n",
        "Fit the model with\n",
        "\n",
        "1. 200 epochs\n",
        "2. batch size of 32\n",
        "\n",
        "No need to print epoch-by epoch progress"
      ],
      "metadata": {
        "id": "6ya2Ecr1Gng0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',  # Adam optimizer\n",
        "    loss='mse',        # Mean Squared Error (MSE) as the loss function\n",
        "    metrics=['mse']    # Mean Squared Error (MSE) as the metric\n",
        ")\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit(\n",
        "    X_train, Y_train,          # Training data\n",
        "    epochs=200,                # Number of epochs\n",
        "    batch_size=32,             # Batch size\n",
        "    validation_data=(X_test, Y_test),  # Validation data\n",
        "    verbose=0                  # Suppress epoch-by-epoch progress\n",
        ")"
      ],
      "metadata": {
        "id": "YGXF1pU5G7IL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: Evaluate Model**\n",
        "\n",
        "Evaluate the model using model.evaluate() with the test set"
      ],
      "metadata": {
        "id": "hLcB_LbWHGkv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "loss, mse = model.evaluate(X_test, Y_test, verbose=0)\n",
        "\n",
        "#Q4-1-13 Print '13. Test MSE: xxx\n",
        "print(f'Test MSE:', mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_HD5zPHHlnm",
        "outputId": "896715e2-2220-4ccb-8d69-bfee547db06e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test MSE: 0.6517770290374756\n"
          ]
        }
      ]
    }
  ]
}